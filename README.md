# GrATS-XAI: Graph-based Attributions for Time Series Explainability
GrATS-XAI introduces a framework for graph-based attributions in time series models, bridging saliency methods to graphs. By using the post-hoc explainers to generate a structured graph, it enables understanding and evaluation of feature interaction and relevance in temporal modelling.

---

## ðŸ“¦ Installation

Clone and set up the environment:

```bash
git clone https://github.com/<your-username>/grats-xai.git
cd grats-xai

# Create conda environment
conda create -n grats python=3.9 -y
conda activate grats

# Install requirements
pip install -r requirements.txt

```


## Project Structure

```
â”œâ”€â”€ configs/               # YAML configs for data generation & experiments
â”‚   â””â”€â”€ data_gen.yaml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ datasets/          # Synthetic DBN generator
â”‚   â”‚   â””â”€â”€ synthetic_dbn.py
â”‚   â”œâ”€â”€ models/            # Simple baselines (e.g. LSTM)
â”‚   â”‚   â””â”€â”€ simple_lstm.py
â”‚   â”œâ”€â”€ explainers/        # Explainability methods (IG, TimeRISE, etc.)
â”‚   â””â”€â”€ evaluation/        # Metrics (infidelity, comprehensiveness, etc.)
â”œâ”€â”€ runs/                  # Auto-saved experiments (ignored via .gitignore)
â””â”€â”€ README.md
```



## ðŸš€ Usage
All supported in the config

```
python scripts/pipeline.py --config configs/pipeline_quick.yaml
```

### 1. Generate synthetic data

Outputs are saved under:

```
runs/dbn_n{params}/
  â”œâ”€â”€ train.pkl
  â”œâ”€â”€ val.pkl
  â””â”€â”€ plots/
```
### 2. Train a model


### 3. Run explainability

Choose an explainer:

    # Integrated Gradients
    # TimeRISE
// TODO:
  Integrated Hessians

## ðŸ“Š Example Output


